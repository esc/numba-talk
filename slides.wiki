== Introduction ==

==== @whoami@ ====

* Senior Software Engineer at Anaconda
* Working on Numba full-time
* Doing this for almost 7 years
* Actively involved in:
** Typed containers
** Release and community management
** Structured Control Flow Graphs

==== Outline ====

\tableofcontents[currentsection]

==== Numba ====

<[center]
    <<<images/numba-logo.pdf, scale=0.20>>>
[center]>

==== Numba in a Nutshell ====

* A compiler that might make your code faster
* Requires importing a decorator: @\@jit@
* And decorating functions with it
* Numba = NumPy + Mamba (fast snake)

==== Numba Explained ====

* Numba is a
** just-in-time
** type-specializing
** function compiler
** for accelerating numerically-focused Python

====  LLVM ====

* LLVM is a compiler toolkit
* Numba uses it as a compiler backend
* Access via @llvmlite@

>>>sieve_short.wiki<<<

==== Example ====

\pyfile{code/sieve.py}

==== Example ====[containsverbatim]

\begin{ipythonconsolecode}
In [2]: %timeit sieve.primes.py_func()
11.8 ms ± 109 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)

In [3]: %timeit sieve.primes()
177 µs ± 11.2 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)
\end{ipythonconsolecode}

==== Open Source Status ====

* Several companies and many open source contributors
** several FTE funded to contribute to Numba
** several non-core contributors per release
* Issue and PR lists growing
* Very active community on GitHub, Discourse

==== Community Usage ====

* Download rate via PyPi is \textasciitilde21 Hz (audible by goldfish)
* GitHub: 163126 Repositories and 6513 Packages
* Several high-profile libraries use it:
** PyData Sparse --> sparse matrix implementation
** UMAP --> Uniform Manifold Approximation
** librosa --> Music analysis
** Tardis-SN --> Super Nova Simulator for Type 1a (White Dwarf Nova)
** Pandas --> Dataframe Library
** NumbaDuck --> Fully jitted DuckDB interface
** numba-cuda, pyOMP, numba-hip --> GPU Programming
** Caterva-2 --> Compressed Compute Engine based on Blosc
** many, many more, we eventually stopped keeping track

== Going Deeper ==

==== Outline ====

\tableofcontents[currentsection]

==== Numba Flow ====

<[center]
    <<<images/numba_flowchart.png, scale=0.40>>>
[center]>

==== Internals ====

* Translate Python objects of supported types into representations with no CPython dependencies ("unboxing")
* Compile Python bytecode from your decorated function into machine code.
* Swap calls to builtins and NumPy functions for implementations provided by Numba (or 3rd party Numba extensions)
* Allow LLVM to inline functions, autovectorize loops, and do other optimizations you would expect from a C compiler
* Allow LLVM to exploit the instruction sets of your hardware (SSE, AVX)
* When calling the function, release the GIL if requested
* Convert return values back to Python objects ("boxing")

==== What Numba does not do ====

* Automated translation of CPython or NumPy implementations
* Automatic compilation of 3rd party libraries
* Partial compilation
* Automatic conversion of arbitrary Python types
* Change the layout of data allocated in the interpreter
* Translate entire programs
* Magically make individual NumPy functions faster

==== When is Numba unlikely to help? ====

* Whole program compilation
* Critical functions have already been converted to C or optimized Cython
* Need to interface directly with C++
* Algorithms that are not primarily numerical, e.g. string manipulation
* Exception: Numba can do pretty well at bit manipulation

% >>>llvmlite.wiki<<<

== NumPy Support ==

==== Outline ====

\tableofcontents[currentsection]

==== Implementing NumPy ====

* Numba does not use much of the NumPy C implementations
* (Only some ufuncs are "borrowed".)
* We implement the NumPy API using Numba compatible/supported Python
* Treat NumPy as DSL for array oriented computing

==== Implementing Numpy ====

* Implement: @numpy.linalg.norm@
* For vectors, @ord@ is:
** @inf@ --> @min(abs(x))@
** @0  @ --> @sum(x != 0)@
* Implemented in: @numba.targets.linalg.py@ 

==== Implementing Numpy ====[containsverbatim]

\begin{pycode}
    elif ord == -np.inf:
        # min(abs(a))
        ret = abs(a[0])
        for k in range(1, n):
            val = abs(a[k])
            if val < ret:
                ret = val
        return ret

    elif ord == 0:
        # sum(a != 0)
        ret = 0.0
        for k in range(n):
            if a[k] != 0.:
                ret += 1.
        return ret
\end{pycode}

== Tips and Tricks ==

==== Outline ====

\tableofcontents[currentsection]

==== Tips and Tricks ====

* Always use @\@jit@
* Prefer NumPy arrays for numerical data
* Use typed containers from @numba.typed@ for nested data
* @for@ loops are fine
* Array expressions are fused if on the same line, so those are fine too

==== Typed Containers ====[containsverbatim]

\pyfile{code/typed.py}

==== Typed Containers ====[containsverbatim]

\begin{consolecode}
$ python code/typed.py
[[0, 1, 2, 3, 4], [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]]
[[0, 1, 2, 3, 4], [23, 23, 23, 23, 23, 23, 23, 23, 23, 23]]
\end{consolecode}

==== Fused Expressions ====[containsverbatim]

\pyfile{code/fused.py}

==== Fused Expressions ====[containsverbatim]

\begin{ipythonconsolecode}
In [1]: from fused import a,b,func

In [2]: %timeit func.py_func(a,b)
4.68 ms ± 89.7 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)

In [3]: %timeit func(a,b)
626 µs ± 22.4 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)
\end{ipythonconsolecode}

==== OS and Hardware Support ====

* Windows 7 and later 64-bit only
* macOS 10.9 and later, @x86\_64@ (Intel) and @arm64@ (M1, M2 etc...)
* Linux @x86\_64@ and @aarch64@ (no @ppc64le@ anymore)
* NVIDIA CUDA GPUs (Compute capability 5.3 and later, CUDA 11.2 and later)
** --> currently being refactored into separate package @numba-cuda@

==== Python versions ====

* Python 3.10 - 3.13 as of Numba 0.62 and llvmlite 0.43

==== Packaging ====

* You can depend on Numba to perform the heavy lifting!
* We run CI on most Python/NumPy/OS/Hardware combinations
* You can ship a single source package
** PyPi
** anaconda.org
* No need to pre-compile binaries for your users

== Compiler Toolkit ==

==== Outline ====

\tableofcontents[currentsection]

==== @inspect@ methods ====[containsverbatim]

* There are various @inspect@ methods on compiled functions
** @inspect\_types@  --> Prints out results from type-inference
** @inspect\_llvm@   --> Obtain LLVM IR
** @inspect\_asm@    --> Obtain print out of function assembly
** @inspect\_cfg@    --> Obtain Control Flow Graph
** @inspect\_dissam\_cfg@  --> Control Flow Graph and disassembly from reversing generated ELF

==== Custom Compiler Passes ====

\pyfile{code/new_pass.py}

==== Custom Compiler Passes ====

\pyfile{code/new_pass_code.py}

==== Custom Compiler Passes ====

\pyfile{code/pipeline.py}

==== Custom Compiler Passes ====

\pyfile{code/use_pipeline.py}

== Summary ==

==== Outline ====

\tableofcontents[currentsection]

==== Understood Numba? ====

* Numba is a
** just-in-time
** type-specializing
** function compiler
** for accelerating numerically-focused Python

==== What is Cooking? ====

* Currently in a PR cleanup, hoping to reduce number of open PRs
* Next gen: numbacc compiler based on Equality Saturation
* PIXIE based backend, toolchain and executable format

==== Getting in Touch ====

* https://numba.pydata.org
* https://github.com/numba
* https://numba.discourse.group/
* Preferred: GitHub + Discourse

* Stuck? It can't hurt to ask. ;-)
