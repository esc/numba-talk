== Introduction ==

==== @whoami@ ====

* Compiler Engineer at Anaconda
* Working on Numba full-time
* Doing this since over 5 years
* Actively involved in:
** Typed containers
** Release and community management
** Compiler frontend design and implementation

==== Outline ====

\tableofcontents[currentsection]

==== Numba ====

<[center]
    <<<images/numba-logo.pdf, scale=0.20>>>
[center]>

==== Numba in a Nutshell ====

* A compiler that might make your code faster
* Requires importing a decorator: @\@njit@
* And decorating functions with it
* Numba = NumPy + Mamba (fast snake)

==== Numba Explained ====

* Numba is a
** just-in-time
** type-specializing
** function compiler
** for accelerating numerically-focused Python

====  LLVM ====

* LLVM is a compiler toolkit
* Numba uses it as a compiler backend
* Access via @llvmlite@

>>>sieve_short.wiki<<<

==== Example ====

\pyfile{code/sieve.py}

==== Example ====[containsverbatim]

\begin{ipythonconsolecode}
In [5]: %timeit sieve.primes.py_func()
124 ms ± 2.72 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)

In [6]: %timeit sieve.primes()
308 µs ± 8.93 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)
\end{ipythonconsolecode}

==== Open Source Status ====

* Several companies and many open source contributors
** 5 FTE funded to contribute to Numba between Anaconda, Intel, Quansight, Nvidia, Bodo.ai and others
** 7-12 non-core contributors per release (~ every 3 months)
* Slowly moving towards NumFocus application
* Issue and PR lists growing
* Very active community on GitHub, Discourse and Gitter


==== Community Usage ====

* Millions of Downloads per month
* On GitHub about 120k repositories are listed as dependents (Oct 2024)
* Several high-profile libraries use it:
** PyData Sparse --> sparse matrix implementation
** UMAP --> Uniform Manifold Approximation
** Tardis --> Super Nova Simulator
** many, many more

== Going Deeper ==

==== Outline ====

\tableofcontents[currentsection]

==== Numba Flow ====

<[center]
    <<<images/numba_flowchart.png, scale=0.40>>>
[center]>

==== Internals ====

* Translate Python objects of supported types into representations with no CPython dependencies ("unboxing")
* Compile Python bytecode from your decorated function into machine code.
* Swap calls to builtins and NumPy functions for implementations provided by Numba (or 3rd party Numba extensions)
* Allow LLVM to inline functions, autovectorize loops, and do other optimizations you would expect from a C compiler
* Allow LLVM to exploit all supported instruction sets of your hardware (SSE, AVX)
* When calling the function, release the GIL if requested
* Convert return values back to Python objects ("boxing")

==== What Numba does not do ====

* Automated translation of CPython or NumPy implementations
* Automatic compilation of 3rd party libraries
* Partial compilation
* Automatic conversion of arbitrary Python types
* Change the layout of data allocated in the interpreter
* Translate entire programs
* Magically make individual NumPy functions faster

==== When is Numba unlikely to help? ====

* Whole program compilation
* Critical functions have already been converted to C or optimized Cython
* Need to interface directly to C++
* Algorithms are not primarily numerical, e.g. strings
* Exception: Numba can do pretty well at bit manipulation

== @llvmlite@ ==

==== Outline ====

\tableofcontents[currentsection]

==== @llvmlite@ ====

* Numba's LLVM binding package
* A "lightweight" Python wrapper
* Not exactly intended as a standalone package, but a few people use it anayway
* Separation of concerns, easier to develop this way
* Uses the C++ API via C -- easier to bind to from Python
* Stability is key, we only upgrade LLVM if necessary, don't chase the bleeding edge

==== @llvmlite@ releases ====

* Released in lock-step with Numba
* About two to four times a year
* Each release only supports one (sometimes two) LLVM versions
** --> several disgruntled users
* Currently we support 14 but transitioning to 15
* ZERO-based versioning
* Patch releases only to fix severe regressions
* No backports

==== @llvmlite@ packages ====

* Numba team creates two types of packages, wheels and conda packages
* The Numba team statically distributes LLVM
* Python wheels for distribution via PyPi
** 20 * 30-40MB
* Conda packages for distribution via the @numba@ channel on anaconda.org
** XXX MB
* Other distributors choose to link dynamically
* (This often creates issues for distributors, since they also only want to support one LLVM version, usually not the one we support but the latest)
* Hot take: LLVM is not a shared library -- but something to be vendored

==== Why not @llvmpy@ ====

* llvmlite comes from an era of LLVM 3.something
* Stability was more important, Numba is the main consumer
* Only the JIT part of LLVM needed (MCJIT)
* For example: our builder-api is entirely in Python and string based
* Better to control the bindings ourselves

== NumPy Support ==

==== Outline ====

\tableofcontents[currentsection]

==== Implementing Numpy ====

* Numba does not use any of the NumPy C implementations
* We implement the NumPy API using Numba compatible/supported Python
* Treat Numpy as DSL for array oriented computing

==== Implementing Numpy ====

* Implement: @numpy.linalg.norm@
* For vectors, @ord@ is:
** @inf@ --> @min(abs(x))@
** @0  @ --> @sum(x != 0)@
* Implemented in: @numba.targets.linalg.py@ 

==== Implementing Numpy ====[containsverbatim]

\begin{pycode}
    elif ord == -np.inf:
        # min(abs(a))
        ret = abs(a[0])
        for k in range(1, n):
            val = abs(a[k])
            if val < ret:
                ret = val
        return ret

    elif ord == 0:
        # sum(a != 0)
        ret = 0.0
        for k in range(n):
            if a[k] != 0.:
                ret += 1.
        return ret
\end{pycode}

== Tips and Tricks ==

==== Outline ====

\tableofcontents[currentsection]

==== Tips and Tricks ====

* Always use @njit
* Prefer Numpy arrays for numerical data
* Use typed containers from @numba.typed@ for nested data
* Use small functions, they are inlined
* @for@ loops are fine
* Array expressions are fused, so those are fine too

==== Typed Containers ====[containsverbatim]

\pyfile{code/typed.py}

==== Typed Containers ====[containsverbatim]

\begin{consolecode}
$ python code/typed.py
[[0, 1, 2, 3, 4], [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]]
[[0, 1, 2, 3, 4], [23, 23, 23, 23, 23, 23, 23, 23, 23, 23]]
\end{consolecode}

==== Fused Expressions ====[containsverbatim]

\pyfile{code/fused.py}

==== Fused Expressions ====[containsverbatim]

\begin{ipythonconsolecode}
In [1]: from fused import a,b,func

In [2]: %timeit func.py_func(a,b)
4.68 ms ± 89.7 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)

In [3]: %timeit func(a,b)
626 µs ± 22.4 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)
\end{ipythonconsolecode}

==== OS and Hardware Support ====

* Windows 7 and later 64-bit only
* macOS 10.9 and later, @x86\_64@ and @arm064@
* Linux (most anything greater than RHEL 5) @x86\_64@ and @aarch64@
* NVIDIA CUDA GPUs (Compute capability 5.3 and later, CUDA 11.2 and later)
** --> currently being refactored into seperate package @numba-cuda@

==== Python versions ====

* Python 3.10 - 3.13 as of Numba 0.62 and llvmlite 0.43
* NumPy YYY

==== Hardware Support ====[containsverbatim]

* x86\_64|AMD64 CPUs
* ARM 64-bit (@aarch64@)
* Apple M1 (@arm64@)

==== Packaging ====

* You can depend on Numba to perform the heavy lifting!
* We run CI on most OS/Python/Hardware combinations
* You can ship a single source package
** PyPi
** anaconda.org
* No need to pre-compile binaries for your users

== Compiler Toolkit ==

==== Outline ====

\tableofcontents[currentsection]

==== @inspect@ methods ====[containsverbatim]

* There are various @inspect@ methods on compiled functions
** @inspect\_types@  --> Printout results from type-inference
** @inspect\_llvm@   --> Obtain LLVM IR representation
** @inspect\_asm@    --> Obtain assembly representation
** @inspect\_cfg@    --> Obtain Control Flow Graph
** @inspect\_dissam\_cfg@  --> Reversed Control Flow Graph from generated ELF

==== Custom Compiler Passes ====

\pyfile{code/new_pass.py}

==== Custom Compiler Passes ====

\pyfile{code/new_pass_code.py}

==== Custom Compiler Passes ====

\pyfile{code/pipeline.py}

==== Custom Compiler Passes ====

\pyfile{code/use_pipeline.py}

==== Outline ====

\tableofcontents[currentsection]

== Summary? ==

==== Outline ====

\tableofcontents[currentsection]

==== Understood Numba? ====

* Numba is a
** just-in-time
** type-specializing
** function compiler
** for accelerating numerically-focused Python

==== What is Cooking? ====

* AST/Source based frontend
* PIXIE backend format
* Transition from MCJIT --> ORCJIT
* Compiler modularization: `numba-cuda` and `numba-numpy` 
* Refactoring to support NumPy 2.0 type system
* Hindley-Milner style type inference
* EggLog 
* Effectively: complete project overhaul

* 3.11 and a new bytecode analyser
* Python --> Assembly visualizer
* Automatic inspection of NumPy Support
* Scipy + Numba = @numba-scipy@

==== Getting in Touch ====

* https://numba.pydata.org
* Preferred: GitHub + Gitter + Discourse

* Stuck? It can't hurt to ask. ;-)
