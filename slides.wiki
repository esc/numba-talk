== Introduction ==

==== @whoami@ ====

* Compiler Engineer at Anaconda
* Working on Numba full-time
* Doing this since three years

==== Outline ====

\tableofcontents[currentsection]

==== Numba ====

<[center]
    <<<images/numba-logo.pdf, scale=0.20>>>
[center]>

==== Numba in a Nutshell ====

* A compiler that might make your code faster
* Requires importing a decorator
* And decorating functions with it
* Numba = NumPy + Mamba (fast snake)

==== Numba Explained ====

* Numba is a
** just-in-time
** type-specializing
** function compiler
** for accelerating numerically-focused Python

====  LLVM ====

* LLVM is a compiler toolkit
* Numba uses it as a compiler backend
* Access via @llvmlite@

>>>sieve_short.wiki<<<

==== Example ====

\pyfile{code/sieve.py}

==== Example ====[containsverbatim]

\begin{ipythonconsolecode}
In [5]: %timeit sieve.primes.py_func()
124 ms ± 2.72 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)

In [6]: %timeit sieve.primes()
308 µs ± 8.93 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)
\end{ipythonconsolecode}

==== Open Source Status ====

* Several companies and many open source contributors
** 4 FTE funded to contribute to Numba between Anaconda, Intel, Quansight, and others
** 7-12 non-core contributors per release (~ every 2 months)
* Slowly moving towards NumFocus application
* Issue and PR lists growing

== Going Deeper ==

==== Outline ====

\tableofcontents[currentsection]

==== Numba Flow ====

<[center]
    <<<images/numba_flowchart.png, scale=0.40>>>
[center]>

==== Internals ====

* Translate Python objects of supported types into representations with no CPython dependencies ("unboxing")
* Compile Python bytecode from your decorated function into machine code.
* Swap calls to builtins and NumPy functions for implementations provided by Numba (or 3rd party Numba extensions)
* Allow LLVM to inline functions, autovectorize loops, and do other optimizations you would expect from a C compiler
* Allow LLVM to exploit all supported instruction sets of your hardware (SSE, AVX)
* When calling the function, release the GIL if requested
* Convert return values back to Python objects ("boxing")

==== What Numba does not do ====

* Automated translation of CPython or NumPy implementations
* Automatic compilation of 3rd party libraries
* Partial compilation
* Automatic conversion of arbitrary Python types
* Change the layout of data allocated in the interpreter
* Translate entire programs
* Magically make individual NumPy functions faster

==== When is Numba unlikely to help? ====

* Whole program compilation
* Critical functions have already been converted to C or optimized Cython
* Need to interface directly to C++
* Algorithms are not primarily numerical
* Exception: Numba can do pretty well at bit manipulation

== NumPy Support ==

==== Outline ====

\tableofcontents[currentsection]

==== Implementing Numpy ====

* Numba does not use any of the NumPy C implementations
* We implement the NumPy API using Numba compatible/supported Python
* Treat Numpy as DSL for array oriented computing

==== Implementing Numpy ====

* Implement: @numpy.linalg.norm@
* For vectors, @ord@ is:
** @inf@ --> @min(abs(x))@
** @0  @ --> @sum(x != 0)@
* Implemented in: @numba.targets.linalg.py@ 

==== Implementing Numpy ====[containsverbatim]

\begin{pycode}
    elif ord == -np.inf:
        # min(abs(a))
        ret = abs(a[0])
        for k in range(1, n):
            val = abs(a[k])
            if val < ret:
                ret = val
        return ret

    elif ord == 0:
        # sum(a != 0)
        ret = 0.0
        for k in range(n):
            if a[k] != 0.:
                ret += 1.
        return ret
\end{pycode}

== Tips and Tricks ==

==== Outline ====

\tableofcontents[currentsection]

==== Tips and Tricks ====

* Always use @jit(nopython=True)@
* (Or @njit@)
* Prefer Numpy arrays for numerical data
* Use typed containers from @numba.typed@ for nested data
* Use small functions, they are inlined
* @for@ loops are fine
* Array expressions are fused, so those are fine too

==== Typed Containers ====[containsverbatim]

\pyfile{code/typed.py}

==== Typed Containers ====[containsverbatim]

\begin{consolecode}
$ python code/typed.py
[[0, 1, 2, 3, 4], [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]]
[[0, 1, 2, 3, 4], [23, 23, 23, 23, 23, 23, 23, 23, 23, 23]]
\end{consolecode}

==== Fused Expressions ====[containsverbatim]

\pyfile{code/fused.py}

==== Fused Expressions ====[containsverbatim]

\begin{ipythonconsolecode}
In [1]: from fused import a,b,func

In [2]: %timeit func.py_func(a,b)
4.68 ms ± 89.7 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)

In [3]: %timeit func(a,b)
626 µs ± 22.4 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)
\end{ipythonconsolecode}

==== OS Support ====

* Windows 7 and later, 32 and 64-bit
* macOS 10.9 and later, 64-bit
* Linux (most anything greater than RHEL 5), 32-bit and 64-bit

==== Python versions ====

* Python 2.7, 3.4-3.7
* NumPy 1.10 and later

==== Hardware Support ====[containsverbatim]

* x86, x86\_64|AMD64 CPUs
* NVIDIA CUDA GPUs (Compute capability 3.0 and later, CUDA 8.0 and later)
* AMD GPUs (ROCm on Linux)
* ARM 32-bit (Raspbery Pi) and 64-bit (Jetson TX2)
* POWER8|9

==== Packaging ====

* You can depend on Numba to perform the heavy lifting!
* We run CI on most OS/Python/Hardware combinations
* You can ship a single source package
** PyPi
** anaconda.org
* No need to pre-compile binaries for your users

== Summary? ==

==== Outline ====

\tableofcontents[currentsection]

==== Understood Numba? ====

* Numba is a
** just-in-time
** type-specializing
** function compiler
** for accelerating numerically-focused Python

==== What is Cooking? ====

* Dropping Python 2.7 support
* Python --> Assembly visualizer
* Automatic inspection of Numpy Support
* Scipy + Numba (aka Scumba)
* Numba-integration-testing (TexasBBQ)
* AirDask-CI

==== Getting in Touch ====

* https://numba.pydata.org
* Preferred: GitHub + Gitter

* Stuck? It can't hurt to ask. ;-)
